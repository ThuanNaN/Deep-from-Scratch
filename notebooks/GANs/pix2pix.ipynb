{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_name = \"facades\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bash download_pix2pix_dataset.sh facades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision  \n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None, split=\"train\"):\n",
    "        self.transform = torchvision.transforms.Compose(transforms)\n",
    "\n",
    "        self.files = sorted(glob.glob(os.path.join(root, split) + \"/*.*\"))\n",
    "        # if split == \"train\":\n",
    "        #     self.files.extend(sorted(glob.glob(os.path.join(root, \"test\") + \"/*.*\")))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        w, h = img.size\n",
    "        img_A = img.crop((0, 0, w / 2, h))\n",
    "        img_B = img.crop((w / 2, 0, w, h))\n",
    "\n",
    "        if np.random.random() < 0.5:\n",
    "            img_A = Image.fromarray(np.array(img_A)[:, ::-1, :], \"RGB\")\n",
    "            img_B = Image.fromarray(np.array(img_B)[:, ::-1, :], \"RGB\")\n",
    "\n",
    "        img_A = self.transform(img_A)\n",
    "        img_B = self.transform(img_B)\n",
    "\n",
    "        return {\"A\": img_A, \"B\": img_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "transforms = [\n",
    "    torchvision.transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "train_set = ImageDataset(root=f\"./data/{dataset_name}\", transforms=transforms, split=\"train\")\n",
    "val_set = ImageDataset(root=f\"./data/{dataset_name}\", transforms=transforms, split=\"val\")\n",
    "# test_set = ImageDataset(root=f\"./data/{dataset_name}\", transforms=transforms, split=\"test\")\n",
    "\n",
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "# test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down1 = DownSample(in_channels, 64, normalize=False)\n",
    "        self.down2 = DownSample(64, 128)\n",
    "        self.down3 = DownSample(128, 256)\n",
    "        self.down4 = DownSample(256, 512)\n",
    "        self.down5 = DownSample(512, 512)\n",
    "        self.down6 = DownSample(512, 512)\n",
    "        self.down7 = DownSample(512, 512)\n",
    "        self.down8 = DownSample(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = UpSample(512, 512, dropout=0.5)\n",
    "        self.up2 = UpSample(1024, 512, dropout=0.5)\n",
    "        self.up3 = UpSample(1024, 512, dropout=0.5)\n",
    "        self.up4 = UpSample(1024, 512, dropout=0.5)\n",
    "        self.up5 = UpSample(1024, 256)\n",
    "        self.up6 = UpSample(512, 128)\n",
    "        self.up7 = UpSample(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, kernel_size=4, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "        return self.final(u7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.InstanceNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.InstanceNorm2d(256),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.InstanceNorm2d(512),\n",
    "\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n",
    "        )\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (down1): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down2): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down3): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down4): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down5): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down6): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down7): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (down8): DownSample(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up1): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up2): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up3): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up4): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (up5): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up6): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up7): UpSample(\n",
       "    (model): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (1): ZeroPad2d((1, 0, 1, 0))\n",
       "    (2): Conv2d(128, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "# generator.apply(weights_init_normal)\n",
    "generator.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (11): ZeroPad2d((1, 0, 1, 0))\n",
       "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "# discriminator.apply(weights_init_normal)\n",
    "\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch_done):\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    imgs = next(iter(val_loader))\n",
    "    real_A = imgs[\"B\"][:5, ...].to(device)\n",
    "    real_B = imgs[\"A\"][:5, ...].to(device)\n",
    "    fake_B = generator(real_A)\n",
    "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
    "    save_image(img_sample, f\"images/epoch_{epoch_done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "\n",
    "save_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train G Loss: 42.4093, Train D Loss: 1.4593\n",
      "Epoch [2/200], Train G Loss: 37.2049, Train D Loss: 0.4381\n",
      "Epoch [3/200], Train G Loss: 36.0657, Train D Loss: 0.5365\n",
      "Epoch [4/200], Train G Loss: 35.3550, Train D Loss: 0.3226\n",
      "Epoch [5/200], Train G Loss: 35.0063, Train D Loss: 0.2795\n",
      "Epoch [6/200], Train G Loss: 34.8417, Train D Loss: 0.3382\n",
      "Epoch [7/200], Train G Loss: 34.3506, Train D Loss: 0.2509\n",
      "Epoch [8/200], Train G Loss: 33.6034, Train D Loss: 0.2037\n",
      "Epoch [9/200], Train G Loss: 33.8627, Train D Loss: 0.2461\n",
      "Epoch [10/200], Train G Loss: 33.4420, Train D Loss: 0.1900\n",
      "Epoch [11/200], Train G Loss: 32.5121, Train D Loss: 0.1728\n",
      "Epoch [12/200], Train G Loss: 32.3047, Train D Loss: 0.2130\n",
      "Epoch [13/200], Train G Loss: 32.0991, Train D Loss: 0.1863\n",
      "Epoch [14/200], Train G Loss: 31.9711, Train D Loss: 0.2086\n",
      "Epoch [15/200], Train G Loss: 31.2567, Train D Loss: 0.1064\n",
      "Epoch [16/200], Train G Loss: 30.8647, Train D Loss: 0.1366\n",
      "Epoch [17/200], Train G Loss: 30.9251, Train D Loss: 0.0998\n",
      "Epoch [18/200], Train G Loss: 30.4462, Train D Loss: 0.0832\n",
      "Epoch [19/200], Train G Loss: 30.2531, Train D Loss: 0.1141\n",
      "Epoch [20/200], Train G Loss: 29.8770, Train D Loss: 0.1282\n",
      "Epoch [21/200], Train G Loss: 29.2697, Train D Loss: 0.1187\n",
      "Epoch [22/200], Train G Loss: 29.6735, Train D Loss: 0.0648\n",
      "Epoch [23/200], Train G Loss: 29.5200, Train D Loss: 0.0922\n",
      "Epoch [24/200], Train G Loss: 28.4830, Train D Loss: 0.0637\n",
      "Epoch [25/200], Train G Loss: 28.3516, Train D Loss: 0.0621\n",
      "Epoch [26/200], Train G Loss: 28.3497, Train D Loss: 0.0452\n",
      "Epoch [27/200], Train G Loss: 27.8711, Train D Loss: 0.0582\n",
      "Epoch [28/200], Train G Loss: 27.8040, Train D Loss: 0.0485\n",
      "Epoch [29/200], Train G Loss: 27.7527, Train D Loss: 0.0389\n",
      "Epoch [30/200], Train G Loss: 26.7719, Train D Loss: 0.0601\n",
      "Epoch [31/200], Train G Loss: 27.1065, Train D Loss: 0.2978\n",
      "Epoch [32/200], Train G Loss: 28.3189, Train D Loss: 2.1076\n",
      "Epoch [33/200], Train G Loss: 26.1516, Train D Loss: 0.3674\n",
      "Epoch [34/200], Train G Loss: 25.2715, Train D Loss: 0.2837\n",
      "Epoch [35/200], Train G Loss: 24.4545, Train D Loss: 0.2640\n",
      "Epoch [36/200], Train G Loss: 24.6402, Train D Loss: 0.2576\n",
      "Epoch [37/200], Train G Loss: 24.9692, Train D Loss: 0.2905\n",
      "Epoch [38/200], Train G Loss: 24.0272, Train D Loss: 0.2413\n",
      "Epoch [39/200], Train G Loss: 24.2759, Train D Loss: 0.2290\n",
      "Epoch [40/200], Train G Loss: 23.7622, Train D Loss: 0.2133\n",
      "Epoch [41/200], Train G Loss: 24.0872, Train D Loss: 0.1932\n",
      "Epoch [42/200], Train G Loss: 23.4102, Train D Loss: 0.2610\n",
      "Epoch [43/200], Train G Loss: 23.3232, Train D Loss: 0.1689\n",
      "Epoch [44/200], Train G Loss: 23.3706, Train D Loss: 0.1037\n",
      "Epoch [45/200], Train G Loss: 24.1472, Train D Loss: 0.1107\n",
      "Epoch [46/200], Train G Loss: 23.4444, Train D Loss: 0.0631\n",
      "Epoch [47/200], Train G Loss: 23.1796, Train D Loss: 0.1144\n",
      "Epoch [48/200], Train G Loss: 23.3548, Train D Loss: 0.0436\n",
      "Epoch [49/200], Train G Loss: 23.1931, Train D Loss: 0.0390\n",
      "Epoch [50/200], Train G Loss: 22.9539, Train D Loss: 0.0363\n",
      "Epoch [51/200], Train G Loss: 23.2039, Train D Loss: 0.0514\n",
      "Epoch [52/200], Train G Loss: 22.5263, Train D Loss: 0.0277\n",
      "Epoch [53/200], Train G Loss: 22.4040, Train D Loss: 0.0291\n",
      "Epoch [54/200], Train G Loss: 23.0317, Train D Loss: 0.0686\n",
      "Epoch [55/200], Train G Loss: 22.4139, Train D Loss: 0.1194\n",
      "Epoch [56/200], Train G Loss: 22.2107, Train D Loss: 0.0443\n",
      "Epoch [57/200], Train G Loss: 22.3822, Train D Loss: 0.0253\n",
      "Epoch [58/200], Train G Loss: 22.6820, Train D Loss: 0.0268\n",
      "Epoch [59/200], Train G Loss: 21.7738, Train D Loss: 0.0269\n",
      "Epoch [60/200], Train G Loss: 22.0329, Train D Loss: 0.0224\n",
      "Epoch [61/200], Train G Loss: 22.2994, Train D Loss: 0.0210\n",
      "Epoch [62/200], Train G Loss: 21.8135, Train D Loss: 0.0338\n",
      "Epoch [63/200], Train G Loss: 21.8410, Train D Loss: 0.0257\n",
      "Epoch [64/200], Train G Loss: 21.5436, Train D Loss: 0.0230\n",
      "Epoch [65/200], Train G Loss: 21.6339, Train D Loss: 0.0167\n",
      "Epoch [66/200], Train G Loss: 21.1833, Train D Loss: 0.0174\n",
      "Epoch [67/200], Train G Loss: 21.1164, Train D Loss: 0.0161\n",
      "Epoch [68/200], Train G Loss: 21.1195, Train D Loss: 0.0202\n",
      "Epoch [69/200], Train G Loss: 21.1106, Train D Loss: 0.0191\n",
      "Epoch [70/200], Train G Loss: 21.1267, Train D Loss: 0.0207\n",
      "Epoch [71/200], Train G Loss: 20.8322, Train D Loss: 0.0229\n",
      "Epoch [72/200], Train G Loss: 21.1628, Train D Loss: 0.0170\n",
      "Epoch [73/200], Train G Loss: 20.7384, Train D Loss: 0.0137\n",
      "Epoch [74/200], Train G Loss: 20.6825, Train D Loss: 0.0161\n",
      "Epoch [75/200], Train G Loss: 20.6841, Train D Loss: 0.0178\n",
      "Epoch [76/200], Train G Loss: 20.4258, Train D Loss: 0.0173\n",
      "Epoch [77/200], Train G Loss: 20.1267, Train D Loss: 0.0135\n",
      "Epoch [78/200], Train G Loss: 20.6102, Train D Loss: 0.0230\n",
      "Epoch [79/200], Train G Loss: 20.6132, Train D Loss: 0.0190\n",
      "Epoch [80/200], Train G Loss: 20.2992, Train D Loss: 0.0149\n",
      "Epoch [81/200], Train G Loss: 20.2853, Train D Loss: 0.0153\n",
      "Epoch [82/200], Train G Loss: 19.8697, Train D Loss: 0.0137\n",
      "Epoch [83/200], Train G Loss: 20.3348, Train D Loss: 0.0142\n",
      "Epoch [84/200], Train G Loss: 20.0678, Train D Loss: 0.0156\n",
      "Epoch [85/200], Train G Loss: 20.1628, Train D Loss: 0.0122\n",
      "Epoch [86/200], Train G Loss: 19.6933, Train D Loss: 0.0129\n",
      "Epoch [87/200], Train G Loss: 19.6184, Train D Loss: 0.0117\n",
      "Epoch [88/200], Train G Loss: 19.5734, Train D Loss: 0.0110\n",
      "Epoch [89/200], Train G Loss: 19.6307, Train D Loss: 0.0175\n",
      "Epoch [90/200], Train G Loss: 19.7301, Train D Loss: 0.0266\n",
      "Epoch [91/200], Train G Loss: 20.0475, Train D Loss: 0.0182\n",
      "Epoch [92/200], Train G Loss: 19.2531, Train D Loss: 0.2397\n",
      "Epoch [93/200], Train G Loss: 19.3761, Train D Loss: 0.1876\n",
      "Epoch [94/200], Train G Loss: 19.1205, Train D Loss: 0.0254\n",
      "Epoch [95/200], Train G Loss: 19.4726, Train D Loss: 0.0169\n",
      "Epoch [96/200], Train G Loss: 19.2720, Train D Loss: 0.0157\n",
      "Epoch [97/200], Train G Loss: 19.1917, Train D Loss: 0.0120\n",
      "Epoch [98/200], Train G Loss: 19.3525, Train D Loss: 0.0114\n",
      "Epoch [99/200], Train G Loss: 19.1534, Train D Loss: 0.0102\n",
      "Epoch [100/200], Train G Loss: 19.3557, Train D Loss: 0.0122\n",
      "Epoch [101/200], Train G Loss: 19.1191, Train D Loss: 0.0142\n",
      "Epoch [102/200], Train G Loss: 18.8907, Train D Loss: 0.0171\n",
      "Epoch [103/200], Train G Loss: 19.0303, Train D Loss: 0.0206\n",
      "Epoch [104/200], Train G Loss: 19.0314, Train D Loss: 0.0115\n",
      "Epoch [105/200], Train G Loss: 18.6551, Train D Loss: 0.0111\n",
      "Epoch [106/200], Train G Loss: 18.6727, Train D Loss: 0.0113\n",
      "Epoch [107/200], Train G Loss: 18.5594, Train D Loss: 0.0112\n",
      "Epoch [108/200], Train G Loss: 18.4509, Train D Loss: 0.0108\n",
      "Epoch [109/200], Train G Loss: 18.9770, Train D Loss: 0.0111\n",
      "Epoch [110/200], Train G Loss: 18.3959, Train D Loss: 0.0098\n",
      "Epoch [111/200], Train G Loss: 18.6530, Train D Loss: 0.0091\n",
      "Epoch [112/200], Train G Loss: 18.7515, Train D Loss: 0.0099\n",
      "Epoch [113/200], Train G Loss: 18.4244, Train D Loss: 0.0105\n",
      "Epoch [114/200], Train G Loss: 18.6153, Train D Loss: 0.0100\n",
      "Epoch [115/200], Train G Loss: 18.7547, Train D Loss: 0.0109\n",
      "Epoch [116/200], Train G Loss: 18.5568, Train D Loss: 0.0107\n",
      "Epoch [117/200], Train G Loss: 18.9053, Train D Loss: 0.0090\n",
      "Epoch [118/200], Train G Loss: 18.3898, Train D Loss: 0.0095\n",
      "Epoch [119/200], Train G Loss: 18.4832, Train D Loss: 0.0111\n",
      "Epoch [120/200], Train G Loss: 18.2560, Train D Loss: 0.0216\n",
      "Epoch [121/200], Train G Loss: 18.5338, Train D Loss: 0.0102\n",
      "Epoch [122/200], Train G Loss: 18.3013, Train D Loss: 0.0081\n",
      "Epoch [123/200], Train G Loss: 18.0728, Train D Loss: 0.0077\n",
      "Epoch [124/200], Train G Loss: 17.9918, Train D Loss: 0.0081\n",
      "Epoch [125/200], Train G Loss: 17.8988, Train D Loss: 0.0082\n",
      "Epoch [126/200], Train G Loss: 17.8861, Train D Loss: 0.0082\n",
      "Epoch [127/200], Train G Loss: 17.8955, Train D Loss: 0.0087\n",
      "Epoch [128/200], Train G Loss: 17.8155, Train D Loss: 0.0095\n",
      "Epoch [129/200], Train G Loss: 18.1807, Train D Loss: 0.0110\n",
      "Epoch [130/200], Train G Loss: 17.7402, Train D Loss: 0.0083\n",
      "Epoch [131/200], Train G Loss: 17.8355, Train D Loss: 0.0071\n",
      "Epoch [132/200], Train G Loss: 17.9217, Train D Loss: 0.0063\n",
      "Epoch [133/200], Train G Loss: 17.5313, Train D Loss: 0.0074\n",
      "Epoch [134/200], Train G Loss: 17.7159, Train D Loss: 0.1810\n",
      "Epoch [135/200], Train G Loss: 17.9524, Train D Loss: 0.3977\n",
      "Epoch [136/200], Train G Loss: 17.6797, Train D Loss: 0.1111\n",
      "Epoch [137/200], Train G Loss: 17.6916, Train D Loss: 0.0222\n",
      "Epoch [138/200], Train G Loss: 17.6301, Train D Loss: 0.0161\n",
      "Epoch [139/200], Train G Loss: 17.3047, Train D Loss: 0.0150\n",
      "Epoch [140/200], Train G Loss: 17.3802, Train D Loss: 0.0164\n",
      "Epoch [141/200], Train G Loss: 17.5521, Train D Loss: 0.0204\n",
      "Epoch [142/200], Train G Loss: 17.4636, Train D Loss: 0.0116\n",
      "Epoch [143/200], Train G Loss: 17.4462, Train D Loss: 0.0096\n",
      "Epoch [144/200], Train G Loss: 17.3173, Train D Loss: 0.0111\n",
      "Epoch [145/200], Train G Loss: 17.3487, Train D Loss: 0.0100\n",
      "Epoch [146/200], Train G Loss: 17.1535, Train D Loss: 0.0106\n",
      "Epoch [147/200], Train G Loss: 17.1994, Train D Loss: 0.0095\n",
      "Epoch [148/200], Train G Loss: 17.1093, Train D Loss: 0.0090\n",
      "Epoch [149/200], Train G Loss: 17.2076, Train D Loss: 0.0098\n",
      "Epoch [150/200], Train G Loss: 17.1975, Train D Loss: 0.0130\n",
      "Epoch [151/200], Train G Loss: 17.0838, Train D Loss: 0.0900\n",
      "Epoch [152/200], Train G Loss: 17.2221, Train D Loss: 0.0229\n",
      "Epoch [153/200], Train G Loss: 17.1123, Train D Loss: 0.0117\n",
      "Epoch [154/200], Train G Loss: 17.2656, Train D Loss: 0.0113\n",
      "Epoch [155/200], Train G Loss: 17.2845, Train D Loss: 0.0130\n",
      "Epoch [156/200], Train G Loss: 16.9391, Train D Loss: 0.0237\n",
      "Epoch [157/200], Train G Loss: 16.9605, Train D Loss: 0.0295\n",
      "Epoch [158/200], Train G Loss: 17.2853, Train D Loss: 0.0120\n",
      "Epoch [159/200], Train G Loss: 17.0918, Train D Loss: 0.0134\n",
      "Epoch [160/200], Train G Loss: 16.9196, Train D Loss: 0.0193\n",
      "Epoch [161/200], Train G Loss: 16.9850, Train D Loss: 0.0153\n",
      "Epoch [162/200], Train G Loss: 16.9169, Train D Loss: 0.0426\n",
      "Epoch [163/200], Train G Loss: 16.9026, Train D Loss: 0.0168\n",
      "Epoch [164/200], Train G Loss: 17.0067, Train D Loss: 0.0129\n",
      "Epoch [165/200], Train G Loss: 17.1130, Train D Loss: 0.0160\n",
      "Epoch [166/200], Train G Loss: 17.1900, Train D Loss: 0.0165\n",
      "Epoch [167/200], Train G Loss: 16.8571, Train D Loss: 0.0139\n",
      "Epoch [168/200], Train G Loss: 16.7375, Train D Loss: 0.1721\n",
      "Epoch [169/200], Train G Loss: 16.6485, Train D Loss: 0.0569\n",
      "Epoch [170/200], Train G Loss: 16.5382, Train D Loss: 0.0307\n",
      "Epoch [171/200], Train G Loss: 16.5520, Train D Loss: 0.0396\n",
      "Epoch [172/200], Train G Loss: 16.9717, Train D Loss: 0.0207\n",
      "Epoch [173/200], Train G Loss: 16.7122, Train D Loss: 0.0179\n",
      "Epoch [174/200], Train G Loss: 16.8897, Train D Loss: 0.0293\n",
      "Epoch [175/200], Train G Loss: 16.7839, Train D Loss: 0.0196\n",
      "Epoch [176/200], Train G Loss: 16.6817, Train D Loss: 0.0168\n",
      "Epoch [177/200], Train G Loss: 16.6014, Train D Loss: 0.0245\n",
      "Epoch [178/200], Train G Loss: 16.5515, Train D Loss: 0.0147\n",
      "Epoch [179/200], Train G Loss: 16.4961, Train D Loss: 0.0540\n",
      "Epoch [180/200], Train G Loss: 16.5451, Train D Loss: 0.0223\n",
      "Epoch [181/200], Train G Loss: 16.6527, Train D Loss: 0.0136\n",
      "Epoch [182/200], Train G Loss: 16.7640, Train D Loss: 0.0112\n",
      "Epoch [183/200], Train G Loss: 16.4170, Train D Loss: 0.0099\n",
      "Epoch [184/200], Train G Loss: 16.4454, Train D Loss: 0.0097\n",
      "Epoch [185/200], Train G Loss: 16.1590, Train D Loss: 0.0092\n",
      "Epoch [186/200], Train G Loss: 16.3081, Train D Loss: 0.0081\n",
      "Epoch [187/200], Train G Loss: 16.5172, Train D Loss: 0.0077\n",
      "Epoch [188/200], Train G Loss: 16.2974, Train D Loss: 0.0096\n",
      "Epoch [189/200], Train G Loss: 16.1150, Train D Loss: 0.0088\n",
      "Epoch [190/200], Train G Loss: 16.1891, Train D Loss: 0.0086\n",
      "Epoch [191/200], Train G Loss: 16.2272, Train D Loss: 0.0084\n",
      "Epoch [192/200], Train G Loss: 16.1490, Train D Loss: 0.0103\n",
      "Epoch [193/200], Train G Loss: 16.4122, Train D Loss: 0.0082\n",
      "Epoch [194/200], Train G Loss: 16.2025, Train D Loss: 0.0084\n",
      "Epoch [195/200], Train G Loss: 16.3169, Train D Loss: 0.0091\n",
      "Epoch [196/200], Train G Loss: 16.2955, Train D Loss: 0.0082\n",
      "Epoch [197/200], Train G Loss: 16.1660, Train D Loss: 0.0079\n",
      "Epoch [198/200], Train G Loss: 16.2323, Train D Loss: 0.0116\n",
      "Epoch [199/200], Train G Loss: 16.1889, Train D Loss: 0.0161\n",
      "Epoch [200/200], Train G Loss: 16.0748, Train D Loss: 0.0094\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "lambda_pixel = 100\n",
    "patch = (1, img_height // 2 ** 4, img_width // 2 ** 4)\n",
    "\n",
    "hist = {\n",
    "        \"train_G_loss\": [],\n",
    "        \"train_D_loss\": [],\n",
    "    }\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_G_loss = 0.0\n",
    "    running_D_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        \n",
    "        real_imgs_A = batch[\"B\"].to(device)\n",
    "        real_imgs_B = batch[\"A\"].to(device)\n",
    "\n",
    "        valid = Tensor(np.ones((real_imgs_A.size(0), *patch))).to(device)\n",
    "        fake = Tensor(np.zeros((real_imgs_A.size(0), *patch))).to(device)\n",
    "\n",
    "        # --- Train Generator ---\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        fake_imgs_B = generator(real_imgs_A)\n",
    "        pred_fake = discriminator(fake_imgs_B, real_imgs_A)\n",
    "\n",
    "        # GAN loss\n",
    "        G_loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "\n",
    "        # Pixel-wise loss\n",
    "        G_loss_pixel = criterion_pixelwise(fake_imgs_B, real_imgs_B)\n",
    "\n",
    "        # Total loss\n",
    "        G_loss = G_loss_GAN + lambda_pixel * G_loss_pixel\n",
    "\n",
    "        running_G_loss += G_loss.item()\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # --- Train Descriminator ---\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(real_imgs_B, real_imgs_A)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "\n",
    "        pred_fake = discriminator(fake_imgs_B.detach(), real_imgs_A)\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "\n",
    "        # Total loss\n",
    "        D_loss = (loss_real + loss_fake) / 2\n",
    "\n",
    "        running_D_loss += D_loss.item()\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    \n",
    "    epoch_G_loss = running_G_loss / len(train_loader)\n",
    "    epoch_D_loss = running_D_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Train G Loss: {epoch_G_loss:.4f}, Train D Loss: {epoch_D_loss:.4f}\")\n",
    "\n",
    "    hist[\"train_G_loss\"].append(epoch_G_loss)\n",
    "    hist[\"train_D_loss\"].append(epoch_D_loss)\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        sample_images(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
