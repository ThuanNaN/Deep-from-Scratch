{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CJatWP7DKqLI"
      },
      "outputs": [],
      "source": [
        "# %pip install -U datasets sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EHFUM-_3KqLK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg1V-YwvKqLK"
      },
      "source": [
        "## 1. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88L4lhXhKqLL"
      },
      "source": [
        "### 1.1 Load dataset English-Vietnamese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lDF8qPS_KqLL"
      },
      "outputs": [],
      "source": [
        "en_vi_dataset = datasets.load_dataset(\"mt_eng_vietnamese\", name=\"iwslt2015-en-vi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNcbpTccKqLL",
        "outputId": "a55d8bcb-05b4-41f3-e48a-43f88dff6a5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 133318\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1269\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1269\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_vi_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPw64ej4KqLM",
        "outputId": "8c2991b1-e45b-4126-fdf2-51ac0fe12bc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'en': 'Rachel Pike : The science behind a climate headline',\n",
              " 'vi': 'Khoa học đằng sau một tiêu đề về khí hậu'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_vi_dataset[\"train\"][0][\"translation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_lzNh_rXKqLN"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"ngocquanofficial/machine_translation_VinAI\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"vi\"\n",
        "prefix = \"translate English to Vietnamese: \"\n",
        "max_input_length = 128    \n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
        "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "en_vi_dataset = en_vi_dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBPOFRAKqLO"
      },
      "source": [
        "## 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LITDFk3UKqLO"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"ngocquanofficial/machine_translation_VinAI\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from transformers.models.t5 import T5ForConditionalGeneration, T5Config\n",
        "\n",
        "# t5_config = T5Config.from_pretrained(\"ngocquanofficial/machine_translation_VinAI\")\n",
        "\n",
        "# model = T5ForConditionalGeneration(config=t5_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3QU_kNnKqLO"
      },
      "source": [
        "## 3. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHYb92v-KqLO"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"out_dir\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=1e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True, \n",
        "    optim=\"adamw_torch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=en_vi_dataset[\"train\"],\n",
        "    eval_dataset=en_vi_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3b86a3395e84303aec937a209256684",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4829, 'learning_rate': 1.9040307101727448e-05, 'epoch': 0.24}\n",
            "{'loss': 1.4554, 'learning_rate': 1.8080614203454897e-05, 'epoch': 0.48}\n",
            "{'loss': 1.4407, 'learning_rate': 1.7120921305182344e-05, 'epoch': 0.72}\n",
            "{'loss': 1.4327, 'learning_rate': 1.616122840690979e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea5a69de92b847e7a5ac7549afbe52a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2264691591262817, 'eval_bleu': 18.8423, 'eval_gen_len': 16.6793, 'eval_runtime': 9.7903, 'eval_samples_per_second': 129.618, 'eval_steps_per_second': 2.043, 'epoch': 1.0}\n",
            "{'loss': 1.3704, 'learning_rate': 1.5201535508637238e-05, 'epoch': 1.2}\n",
            "{'loss': 1.3575, 'learning_rate': 1.4241842610364684e-05, 'epoch': 1.44}\n",
            "{'loss': 1.3622, 'learning_rate': 1.3282149712092132e-05, 'epoch': 1.68}\n",
            "{'loss': 1.3649, 'learning_rate': 1.2322456813819578e-05, 'epoch': 1.92}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "473f25cb87f34ba0aa4d0462e430e84c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.222044587135315, 'eval_bleu': 18.8403, 'eval_gen_len': 16.6777, 'eval_runtime': 9.6858, 'eval_samples_per_second': 131.017, 'eval_steps_per_second': 2.065, 'epoch': 2.0}\n",
            "{'loss': 1.3248, 'learning_rate': 1.1362763915547026e-05, 'epoch': 2.16}\n",
            "{'loss': 1.3088, 'learning_rate': 1.0403071017274472e-05, 'epoch': 2.4}\n",
            "{'loss': 1.3098, 'learning_rate': 9.44337811900192e-06, 'epoch': 2.64}\n",
            "{'loss': 1.3039, 'learning_rate': 8.483685220729368e-06, 'epoch': 2.88}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cb315ebac064a0b9af6c1dada66ef49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2216891050338745, 'eval_bleu': 18.9997, 'eval_gen_len': 16.6359, 'eval_runtime': 9.4092, 'eval_samples_per_second': 134.868, 'eval_steps_per_second': 2.126, 'epoch': 3.0}\n",
            "{'loss': 1.2802, 'learning_rate': 7.523992322456814e-06, 'epoch': 3.12}\n",
            "{'loss': 1.2641, 'learning_rate': 6.5642994241842614e-06, 'epoch': 3.36}\n",
            "{'loss': 1.2683, 'learning_rate': 5.6046065259117085e-06, 'epoch': 3.6}\n",
            "{'loss': 1.2739, 'learning_rate': 4.644913627639156e-06, 'epoch': 3.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "189bc914df14461a8c7f11144bdc3fcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2213001251220703, 'eval_bleu': 19.0839, 'eval_gen_len': 16.647, 'eval_runtime': 9.4148, 'eval_samples_per_second': 134.788, 'eval_steps_per_second': 2.124, 'epoch': 4.0}\n",
            "{'loss': 1.2641, 'learning_rate': 3.687140115163148e-06, 'epoch': 4.08}\n",
            "{'loss': 1.2443, 'learning_rate': 2.727447216890595e-06, 'epoch': 4.32}\n",
            "{'loss': 1.2433, 'learning_rate': 1.7677543186180424e-06, 'epoch': 4.56}\n",
            "{'loss': 1.2417, 'learning_rate': 8.080614203454896e-07, 'epoch': 4.8}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88c00a7c80cd42b6972c08fd091d2a5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2219176292419434, 'eval_bleu': 19.0503, 'eval_gen_len': 16.6344, 'eval_runtime': 9.5111, 'eval_samples_per_second': 133.423, 'eval_steps_per_second': 2.103, 'epoch': 5.0}\n",
            "{'train_runtime': 3994.2477, 'train_samples_per_second': 166.887, 'train_steps_per_second': 2.609, 'train_loss': 1.3263574289040008, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10420, training_loss=1.3263574289040008, metrics={'train_runtime': 3994.2477, 'train_samples_per_second': 166.887, 'train_steps_per_second': 2.609, 'train_loss': 1.3263574289040008, 'epoch': 5.0})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "206b117004c548faaf4b5c629aecde49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.2213001251220703,\n",
              " 'eval_bleu': 19.0839,\n",
              " 'eval_gen_len': 16.647,\n",
              " 'eval_runtime': 9.4567,\n",
              " 'eval_samples_per_second': 134.191,\n",
              " 'eval_steps_per_second': 2.115,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(eval_dataset=en_vi_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pre-trained model: ngocquanofficial/machine_translation_VinAI\n",
        "\n",
        "# - eval_only - 0 epoch\n",
        "#     - loss: 1.7319\n",
        "#     - BLEU: 16.7368\n",
        "\n",
        "# - fine_tune - 5 epochs 2e-5\n",
        "#     - loss: 1.2213\n",
        "#     - BLEU: 19.0839\n",
        "    \n",
        "# - cfg_only - 10 epochs 1e-4\n",
        "#     - loss: 3.209\n",
        "#     - BLEU: 6.9639\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Tôi đang học cách dịch nó ra tiếng'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_input = \"I am learning how to translate\"\n",
        "inputs_ids =  tokenizer.encode(text_input, return_tensors=\"pt\").to(\"cuda\")\n",
        "output_ids = model.generate(inputs_ids, max_length=128, num_return_sequences=1)\n",
        "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
