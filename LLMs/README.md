# Unk-LLMs

## 1. Papers:
- [ ] LLaMA-Adapter. https://arxiv.org/abs/2303.16199
- [ ] LLaMA-Adapter-V2. https://arxiv.org/abs/2304.15010
- [ ] ControlNet. https://arxiv.org/abs/2302.05543
- [ ] RoundingDINO. https://github.com/IDEA-Research/GroundingDINO
- [ ] PhoGPT. https://github.com/VinAIResearch/PhoGPT 
- [ ] RoFormer. https://arxiv.org/abs/2104.09864
- [ ] Perceiver IO. https://arxiv.org/abs/2107.14795
- [ ] Flamingo. https://arxiv.org/abs/2204.14198
- [ ] GPT4-V. https://cdn.openai.com/papers/GPTV_System_Card.pdf
- [ ] PaLM. https://arxiv.org/abs/2204.02311
- [ ] Parameter-Efficient Transfer Learning for NLP. https://arxiv.org/abs/1902.00751
- [ ] Exploring Versatile Generative Language Model Via Parameter-Efficient
- [ ] Transfer Learning. https://aclanthology.org/2020.findings-emnlp.41.pdf
- [ ] LLaVA. https://arxiv.org/abs/2304.08485 - https://github.com/haotian-liu/LLaVA
- [ ] Florence-2. https://arxiv.org/abs/2311.06242
- [ ] A Comprehensive Overview of Large Language Models https://arxiv.org/abs/2307.06435
- [ ] MoV - MoLORA. https://arxiv.org/pdf/2309.05444.pdf

#### Speed-up LLMs
- [ ] Longformer. https://arxiv.org/abs/2004.05150v2
- [ ] Flash-Attention. https://arxiv.org/abs/2205.14135
- [ ] Flash-Attention-2. https://arxiv.org/abs/2307.08691
- [ ] Mamba. https://arxiv.org/abs/2312.00752
- [ ] U-Mamba. https://arxiv.org/abs/2401.04722

#### Optimizer
- [ ] SGD
- [ ] Adam
- [ ] AdamW
- [ ] Adam Believe
- [ ] Sophia Optimizer. https://arxiv.org/abs/2305.14342
- [ ] Lion Optimizer. https://arxiv.org/abs/2302.06675

## 2. Library, Framework
- vLLM. https://docs.vllm.ai/en/latest/index.html

## 3.Vietnamese LLMs
- https://huggingface.co/vilm
- https://huggingface.co/VietAI

## 4. Reference
- https://github.com/openai/openai-cookbook
- https://github.com/mosaicml/llm-foundry
- https://www.promptingguide.ai/
- https://github.com/microsoft/generative-ai-for-beginners
- https://github.com/microsoft/AI-For-Beginners