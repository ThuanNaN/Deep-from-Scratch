## A Survey on Multimodal Large Language Models
- Link paper: https://arxiv.org/abs/2306.13549
- Github: https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models

### Keywords:
- Large Language Models (LLMs)
- Multimodal Large Language Model (MLLM)
- Artificial General Intelligence (AGI)

### Concepts:
- OCR-free math reasoning. https://arxiv.org/abs/2303.03378
- Chain of Thought (CoT). https://arxiv.org/abs/2201.11903
- Zero-shot-CoT. https://arxiv.org/abs/2205.11916

### Taxonomy:
#### 1. Multimodal Instruction Tuning (M-IT)
- Instruction-formatted datasets. https://arxiv.org/abs/2109.01652
- Self-Intruction. https://arxiv.org/abs/2212.10560
- LLaVA - Visual Intrucion Tuning. https://arxiv.org/abs/2304.08485
- Learnable Interface:
    - Flamingo. https://arxiv.org/abs/2204.14198
    - BLIP-2. https://arxiv.org/abs/2301.12597

#### 2. Multimodal In-Context Learning (M-ICL)


#### 3. Multimodal Chain-of-Thought (M-CoT)


#### 4. LLM-Aided Visual Reasoning (LAVR)
- Roles:
    - LLM as a Controller
        - HuggingGPT. https://arxiv.org/abs/2303.17580
        - GPT4Tool. https://arxiv.org/abs/2305.18752
    - LLM as a Decision Maker
    - LLM as a Semantics Refiner


